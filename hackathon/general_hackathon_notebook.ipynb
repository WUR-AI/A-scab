{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 🍏 Welcome to the **Smart Droplets Hackathon**!\n",
    "\n",
    "![image](assets/sd_logo.png)\n",
    "\n",
    "The Smart Droplets project is an EU-funded project, focusing on achieving reduced pesticide and fertilizer use with techniques of Digital Twins and Reinforcement Learning. One of the pilot projects of Smart Droplets is about the reduction of the **apple scab** pest.\n",
    "In commercial apple production, **apple scab (_Venturia inaequalis_)** is the most economically important disease. Growers traditionally rely on **calendar-based fungicide programs**, which can lead to unnecessary sprays, resistance, and environmental impact.\n",
    "In this hackathon we’ll flip that paradigm: **you will train a reinforcement-learning (RL) agent, or an intelligent conditional agent, to decide _when_ (and _how much_) to spray, balancing disease risk with sustainability.**\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 The Challenge\n",
    "\n",
    "**Goal**: **Learn an optimal and adaptive spraying policy.**\n",
    "\n",
    "**How to achieve that?**: Use **RL** to interact with the **A-scab** disease simulator. Your agent chooses daily actions (“spray how much” vs. “don’t spray”) through an entire season, to reduce the risk of breakout.\n",
    "\n",
    "**Why is this important?** Smarter timing reduces chemical use, lowers costs, and lowers environmental impact while keeping orchards healthy to reduce yield loss.\n",
    "\n",
    "Success is measured by a **cumulative reward**:\n",
    "\n",
    "$R_t = - Risk_{t} - \\beta P_t$\n",
    "\n",
    "* $Risk$ is **Infection risk** – cumulative infection severity at harvest\n",
    "* $\\beta$ is **trade-off coefficient** - coefficient describing economic and ecological price of pesticides\n",
    "* $P$ is **Pesticide amount** – the amount of pesticide sprayed\n",
    "\n",
    "A higher score is better -- closer to zero!\n",
    "\n",
    "---\n",
    "\n",
    "## 🌱 The Environment: **Ascabgym**\n",
    "\n",
    "Ascabgym is a stochastic, weather-driven model of apple scab dynamics, based on the A-scab model.\n",
    "At each daily time step, an agent can observe the following features:\n",
    "\n",
    "* _Weather features_: Temperature, relative humidity, rainfall, and leaf wetness\n",
    "    * also 1 day and 2 day forecasts of the above weather features\n",
    "* _Pest features_: ascopore maturity & development\n",
    "* _Tree features_: leaf area index and phenology\n",
    "\n",
    "…and updates disease progress based on your action. We expose a **Gymnasium-style API** so you can plug in any RL library (Stable-Baselines3, RLlib, CleanRL, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "## 📂 Data & Starter Kit\n",
    "\n",
    "* **Historical weather files** for training the model, files from several locations in Europe (CSV).\n",
    "* **Default orchard parameters** which are already embedded in the model\n",
    "* Performance of baseline agents to beat!\n",
    "\n",
    "% Clone the repo or fork the Kaggle notebook, pip-install extra libraries as needed, and start experimenting.\n",
    "\n",
    "---\n",
    "\n",
    "## 🏆 Evaluation & Leaderboards\n",
    "\n",
    "1. **Local validation** – run episodes on the provided weather years (fast iteration).\n",
    "2. **Public leaderboard** – on submission, Kaggle simulates **four hidden seasons** from a particular location and reveals your average score.\n",
    "3. **Private leaderboard** (final ranking) – after the deadline we evaluate on **five additional unseen seasons** to prevent overfitting.\n",
    "\n",
    "> **Tip:** Aim for generalisation, not leaderboard-hacking!\n",
    "\n",
    "---\n",
    "\n",
    "## ✋ Rules of the Game\n",
    "\n",
    "| Topic | Rule                                                                                               |\n",
    "|-------|----------------------------------------------------------------------------------------------------|\n",
    "| **External data** | In general, the use of external data is not allowed.                                               |\n",
    "| **Compute** | Submissions must run < **3 hours on Kaggle’s 2×V100** quota.                                       |\n",
    "| **Team size** | Individual!                                                                                        |\n",
    "| **Fair play** | No model-sharing between teams until after the hackathon closes. Respect Kaggle’s Code of Conduct. |\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Resources\n",
    "\n",
    "* **A-scab docs** (PDF + API reference)\n",
    "* **RL documentation** (Stable Baselines 3 documentation)\n",
    "\n",
    "---\n"
   ],
   "id": "458e825b680bf709"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 🚀 First things first\n",
    "\n",
    "Install all the necessary packages. Feel free to install the RL framework you feel most comfortable working with. By default, you can use Stable Baselines 3. Make sure to install the hackathon version of the A-scab repository."
   ],
   "id": "551061fc3142e30a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#clone the repository and install AscabGym\n",
    "!rm -rf A-scab/\n",
    "!git clone -b hackathon https://github.com/WUR-AI/A-scab.git\n",
    "#change directory\n",
    "%cd A-scab\n",
    "#install poetry if needed.\n",
    "!pip install -qqq poetry\n",
    "\n",
    "#install; this step may take 5 minutes\n",
    "!poetry config virtualenvs.in-project true\n",
    "!poetry install --quiet --all-extras\n",
    "\n",
    "# These are things you don't need to know about for now :)\n",
    "import os, sys\n",
    "\n",
    "VENV_PATH = \"/content/A-scab/.venv/lib/python3.11/site-packages\"\n",
    "LOCAL_VENV_PATH = '/content/venv' # local notebook\n",
    "os.symlink(VENV_PATH, LOCAL_VENV_PATH) # connect to directory in drive\n",
    "sys.path.insert(0, LOCAL_VENV_PATH)"
   ],
   "id": "f3cafe6104fa35be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# install further packages using poetry, to keep package dependency intact\n",
    "# in general the syntax is `poetry add PACKAGE_NAME`, then install with `poetry install`.\n",
    "# below is an example how to install stable baselines 3\n",
    "\n",
    "!poetry add stable-baselines3\n",
    "!poetry install"
   ],
   "id": "fe2605ff0e5bda89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Initialize the gymnasium environment by importing the necessary methods.\n",
    "\n",
    "This may take 1 minute or so :)"
   ],
   "id": "f6037755e785f884"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import ascab\n",
    "import gymnasium as gym"
   ],
   "id": "c26950f41d5b4447",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For this hackathon, we have provided pre-registered environments that you will only need the ID to call. For example, the code below will construct the AscabGym environment!",
   "id": "6d53b6ece951abbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ascab_train = gym.make('AscabTrainEnv-Discrete')",
   "id": "3196dc192da94e0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The code below will be your validation gym environment, i.e., the place where you test your trained agents! (Note the csv file loaded)",
   "id": "c44ad5787aeb10c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ascab_val = gym.make('AscabValEnv-Discrete')",
   "id": "f140f59007503ac1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Let's get to know the Ascab environment! Gym speed dating?\n",
    "\n",
    "We're gonna introduce to you the _action space_, the _observation space_ and the _goal_ of the A-scab gym environment!\n",
    "\n",
    "### Action space, A.K.A what your agent can do!\n",
    "\n",
    "with the code below, you can check what the agent can do in each timestep!"
   ],
   "id": "8f7517dad01f05dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(ascab_train.action_space)",
   "id": "1f026fcfbe433b82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notice that it is a discrete action space of 20? This corresponds to the following amounts: $ A = \\{0.05\\,i\\,|\\,i=0,1,2,\\dots,20\\}$.\n",
    "\n",
    "You can also use a continuous action spaces, which will have actions of [0, 1]! That will allow the agent to have a more fine-grained decision when spraying.\n",
    "\n",
    "_hint: initialize the environment with `gym.make(AscabTrainEnv-Continuous')`_\n"
   ],
   "id": "6fa68ee07caf18eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Observation space, A.K.A what your agent can see!\n",
    "\n",
    "The in general, the agent can see these following features:\n",
    "...\n",
    "\n",
    "You can also check this through code:\n"
   ],
   "id": "b5666b020728b7ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(ascab_train.observation_space)",
   "id": "ba7aff0227896cd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### What's the goal here?",
   "id": "91d6b641d1705a5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "43a5846c80dbfa85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Example of training your own agent\n",
    "\n",
    "Here we show you how to train your own agent! You can either\n",
    "1. Train an RL agent with your own framework.\n",
    "or\n",
    "2. Create your own intelligence conditional agent!\n",
    "\n",
    "Scroll below for further instructions.\n",
    "\n",
    "### Training with Stable Baselines 3"
   ],
   "id": "f739fb9204a521b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Below we provide an example of training your RL-based pesticide expert with the DQN algorithm, provided by the Stable Baselines 3 algorithm.",
   "id": "1d100b96c80d590f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ascab.train import RLAgent\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "os.makedirs(os.path.join(os.getcwd(), 'rl_model'), exist_ok=True)\n",
    "os.makedirs(os.path.join(os.getcwd(), 'log'), exist_ok=True)\n",
    "\n",
    "rl_agent = RLAgent(\n",
    "    ascab_train=ascab_train,\n",
    "    ascab_test=ascab_val,\n",
    "    observation_filter=list(ascab_train.observation_space.keys()),\n",
    "    render=False,\n",
    "    path_model=os.path.join(os.getcwd(), 'rl_model'),\n",
    "    path_log=os.path.join(os.getcwd(), 'log'),\n",
    "    rl_algorithm=DQN,  # feed in the constructor of the Stable Baselines 3 model\n",
    "    seed=107,  # use random seed if you like to\n",
    "    n_steps=50_000  #train it for 50k steps. NOTE: This is no where near enough for an agent to learn\n",
    ")"
   ],
   "id": "c58f4a5c7657e7d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If you don't want to use the Stable Baselines 3 framework, you can of course start training using any RL framework you prefer, starting by using the `ascab_train` gym environment defined above.\n",
    "\n",
    "### Don't want to use RL? No problem, we got you!\n",
    "It's nevertheless possible to create your own non-RL agent; a conditional agent!\n",
    "One conditional agent could be a spraying schedule based on calendar date. This strategy is typically employed by farmers. Here's an example of how to do it:\n",
    "\n",
    "### Example of creating a conditional agent"
   ],
   "id": "d0faeacd9a60596d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datetime import datetime\n",
    "from ascab.train import BaseAgent\n",
    "from ascab.env.env import AScabEnv\n",
    "\n",
    "# First define the class, not forgetting to SubClass `BaseAgent`\n",
    "# In general, you want to change the get_action method to apply your conditional spraying strategy\n",
    "class HowMyLocalFarmerSprays(BaseAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ascab: AScabEnv = None,\n",
    "        render: bool = True,\n",
    "        dates: list[datetime.date] = None\n",
    "    ):\n",
    "        super().__init__(ascab=ascab, render=render)\n",
    "        if dates is None:\n",
    "            year = self.ascab.get_wrapper_attr(\"date\").year\n",
    "            dates = [datetime.date(year, 3, 20), datetime.date(year, 4, 1), datetime.date(year, 4, 8)]  # dates you want to spray\n",
    "        self.dates = dates\n",
    "\n",
    "    def get_action(self, observation: dict = None) -> float:\n",
    "        if self.ascab.get_wrapper_attr(\"info\")[\"Date\"] and self.ascab.get_wrapper_attr(\"info\")[\"Date\"][-1] in self.dates:\n",
    "            return 1.0  # you spray this much if when it is the date arrives\n",
    "        return 0.0\n"
   ],
   "id": "1c4be5e87aa44125"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then, you can try and run your expert strategy in the validation environment!",
   "id": "2103ce780c3ba443"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "farmer_strategy = HowMyLocalFarmerSprays(ascab_val)\n",
    "farmer_strategy_results = farmer_strategy.run()"
   ],
   "id": "eecb4f1d2b57b667"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "How did it do? Continue experimenting for the best spraying strategy!\n",
    "\n",
    "Also, you can evaluate a trained RL agent the same way:"
   ],
   "id": "62049c085012d60e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "rl_results = rl_agent.run()",
   "id": "6815391363580107"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Want to check out how your agent did?\n",
    "\n",
    "Use the code below to plot results after using the `.run()` method!"
   ],
   "id": "f0b18575a6a5e30f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ascab.utils.plot import plot_results\n",
    "\n",
    "\n",
    "# First, make a dictionary of your agents\n",
    "dict_to_plot = {\"RL\":rl_results,\n",
    "             \"MyFarmer\":farmer_strategy_results,}\n",
    "\n",
    "plot_results(\n",
    "            dict_to_plot,\n",
    "            variables=[\n",
    "                 \"Precipitation\",\n",
    "                 \"AscosporeMaturation\",\n",
    "                 \"Discharge\",\n",
    "                 \"Pesticide\",\n",
    "                 \"Risk\",\n",
    "                 \"Action\",\n",
    "            ],\n",
    "            save_path=os.getcwd(),\n",
    "            per_year=True,\n",
    "        )"
   ],
   "id": "710489b108fb12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "How did your agent(s) do? Not satisfied? Try another strategy or RL agent!",
   "id": "d03db76ca3f98aee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Instructions for submitting your winning Agent",
   "id": "6a57cdb962862704"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Obs space is fixed; allowed features\n",
    "2. Training file is fixed\n",
    "3. We provide Val file\n",
    "4. Testing for leaderboard will be done in unseen location"
   ],
   "id": "f06034d867248497"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ed0b143cd6f83b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
