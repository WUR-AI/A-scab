{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ Welcome to the **Smart Droplets Hackathon Submission**!\n",
        "\n",
        "This notebook is designed to help you test and submit your solution for the Smart Droplets Hackathon.\n",
        "You can use it to validate and evaluate either:\n",
        "\n",
        "\n",
        "*   A trained Reinforcement Learning (RL) agent, or\n",
        "\n",
        "*   A Conditional Agent\n",
        "\n",
        "Please make sure to follow the instructions in each section carefully. Good luck â€” and have fun!\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/WUR-AI/A-scab/blob/hackathon/hackathon/submit_hackathon.ipynb)"
      ],
      "metadata": {
        "id": "yJP0G6QhD4nQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“ Make a Copy Before You Start\n",
        "\n",
        "> ðŸŸ¡ **IMPORTANT:** Please make a copy of this notebook **before** uploading or running anything.\n",
        ">\n",
        "> Go to: `File` â†’ `Save a copy in Drive`\n",
        ">\n",
        "> This ensures:\n",
        "> - You can save your work as you go\n",
        "> - Uploaded files and trained agents stay accessible\n",
        "> - Youâ€™ll be able to export everything at the end\n",
        "\n",
        "âž¡ï¸ Once you've made a copy, continue below.\n"
      ],
      "metadata": {
        "id": "omsS-iQiXcWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup\n",
        "Before testing your agent, please make sure the environment is properly set up. Use the cell below to import dependencies and initialize the simulation environment."
      ],
      "metadata": {
        "id": "0OqBVIvzGt_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to set up the environment\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Clone the repository\n",
        "!rm -rf A-scab/\n",
        "!git clone -b hackathon https://github.com/WUR-AI/A-scab.git\n",
        "\n",
        "# Change directory\n",
        "%cd A-scab\n",
        "\n",
        "# Get the absolute path of the project root *after* changing directory\n",
        "PROJECT_ROOT = os.getcwd()\n",
        "\n",
        "# Install poetry if needed.\n",
        "!pip install -qqq poetry\n",
        "\n",
        "# Configure poetry to create virtual environments in the project directory\n",
        "!poetry config virtualenvs.in-project true\n",
        "\n",
        "# Install project dependencies\n",
        "# This step may take some time (e.g., 5 minutes)\n",
        "!poetry install --quiet --all-extras\n",
        "\n",
        "# These are things you don't need to know about for now :)\n",
        "\n",
        "# 1. Add the project root to sys.path\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "    print(f\"Added project root {PROJECT_ROOT} to sys.path\")\n",
        "\n",
        "# 2. Get the path to the site-packages directory of the poetry virtual environment\n",
        "try:\n",
        "    venv_path_output = subprocess.check_output(['poetry', 'env', 'info', '--path']).decode('utf-8').strip()\n",
        "    python_version_major_minor = f\"python{sys.version_info.major}.{sys.version_info.minor}\"\n",
        "    SITE_PACKAGES_PATH = os.path.join(venv_path_output, 'lib', python_version_major_minor, 'site-packages')\n",
        "except Exception as e:\n",
        "    print(f\"Could not determine poetry venv site-packages path using 'poetry env info': {e}\")\n",
        "    print(\"Attempting a common fallback path structure...\")\n",
        "    SITE_PACKAGES_PATH = os.path.abspath(os.path.join('.venv', 'lib', f'python{sys.version_info.major}.{sys.version_info.minor}', 'site-packages'))\n",
        "\n",
        "# 3. Add the site-packages directory to sys.path\n",
        "if os.path.exists(SITE_PACKAGES_PATH) and SITE_PACKAGES_PATH not in sys.path:\n",
        "    sys.path.insert(0, SITE_PACKAGES_PATH)\n",
        "    print(f\"Added {SITE_PACKAGES_PATH} to sys.path\")\n",
        "else:\n",
        "    print(f\"Warning: Could not find site-packages at {SITE_PACKAGES_PATH} or it's already in sys.path.\")\n",
        "\n",
        "import ascab\n",
        "import gymnasium as gym"
      ],
      "metadata": {
        "id": "k2iwv6MgD58j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RL Agent\n",
        "If you have trained a Reinforcement Learning (RL) agent, please use the cell below to test your agent in the simulation environment. This will help validate that your agent behaves as expected and meets the requirements for submission."
      ],
      "metadata": {
        "id": "Cw6h63GjFthO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Your Trained Agent\n",
        "To test your agent, please run the cell below and use the resulting upload button to select and upload your files.\n",
        "\n",
        "Do not manually upload files; the code below ensures files are correctly processed and renamed automatically.\n",
        "\n",
        "Typically, you need to upload:\n",
        "\n",
        "1.   Your trained model file (e.g., `rl_agent.zip`)\n",
        "2.   (Optional) Environment normalization file, if you used one during training (e.g., `rl_agent_norm.pkl`)"
      ],
      "metadata": {
        "id": "TKqRhUf9JMZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Upload files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Create /content if it doesn't exist (mostly for local notebook support)\n",
        "os.makedirs('/content', exist_ok=True)\n",
        "\n",
        "# Standard filenames\n",
        "standard_model_name = \"rl_agent.zip\"\n",
        "standard_norm_name = \"rl_agent_norm.pkl\"\n",
        "\n",
        "def safe_move(src, dst):\n",
        "    if os.path.exists(dst):\n",
        "        os.remove(dst)\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "# Move and rename uploaded files, allowing overwriting\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith(\".zip\") and \"norm\" not in filename.lower():\n",
        "        safe_move(filename, f\"/content/{standard_model_name}\")\n",
        "        print(f\"Renamed and moved '{filename}' â†’ '/content/{standard_model_name}'\")\n",
        "    elif filename.endswith(\".pkl\") or filename.endswith(\".pickle\") or \"norm\" in filename.lower():\n",
        "        safe_move(filename, f\"/content/{standard_norm_name}\")\n",
        "        print(f\"Renamed and moved '{filename}' â†’ '/content/{standard_norm_name}'\")"
      ],
      "metadata": {
        "id": "7CvTlI8EKjmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run you RL agent\n",
        "\n",
        "Now weâ€™ll load your trained RL agent and run it in the test environment.\n",
        "\n",
        "\n",
        "*   By default, it assumes you have used the DQN algorithm. If you trained your\n",
        "*   Similarly, if you customized the observation space, make sure to update the observation_filter to match your modelâ€™s expected inputs"
      ],
      "metadata": {
        "id": "qnbS0RETOKpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ascab.train import RLAgent\n",
        "from ascab.utils.plot import plot_results\n",
        "from stable_baselines3 import PPO, SAC, TD3, DQN, HER\n",
        "\n",
        "ascab_val = gym.make('AscabValEnv-Discrete')\n",
        "\n",
        "algo=DQN\n",
        "observation_filter=list(ascab_val.observation_space.keys())\n",
        "\n",
        "rl_agent = RLAgent(\n",
        "    rl_algorithm=algo,\n",
        "    observation_filter=list(ascab_val.observation_space.keys()),\n",
        "    ascab_test=ascab_val,\n",
        "    path_model='/content/rl_agent',\n",
        ")\n",
        "results = rl_agent.run()"
      ],
      "metadata": {
        "id": "ie87FqGbib0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If Everything Ran Successfully...\n",
        "Congratulations â€” if the last cell ran without errors and you see some rewards appearing, your RL agent is working as expected in the evaluation environment!\n",
        "\n",
        "Youâ€™re now ready to complete your submission. Please run the cell below to download your submission package.\n"
      ],
      "metadata": {
        "id": "m5cI-lWGQJY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "\n",
        "# This will execute JS in the notebook to get the filename\n",
        "def get_notebook_name():\n",
        "    display(Javascript('''\n",
        "        async function getNotebookName() {\n",
        "            const notebookName = document.title.replace(\" - Colaboratory\", \"\").trim();\n",
        "            google.colab.kernel.invokeFunction('notebookNameCallback', [notebookName], {});\n",
        "        }\n",
        "        getNotebookName();\n",
        "    '''))\n",
        "\n",
        "# This sets up the Python callback\n",
        "notebook_name = None\n",
        "\n",
        "def notebook_name_callback(name):\n",
        "    global notebook_name\n",
        "    notebook_name = name\n",
        "    print(f\"ðŸ““ Detected notebook name: {notebook_name}\")\n",
        "\n",
        "output.register_callback('notebookNameCallback', notebook_name_callback)\n",
        "\n",
        "get_notebook_name()\n"
      ],
      "metadata": {
        "id": "nGig_-w7YPGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import time\n",
        "from google.colab import files\n",
        "\n",
        "# Wait a few seconds in case the JS callback takes time\n",
        "time.sleep(2)\n",
        "\n",
        "if notebook_name is None:\n",
        "    print(\"âŒ Notebook name not detected. Please run the previous cell and try again.\")\n",
        "else:\n",
        "    # Create a clean folder for packaging\n",
        "    os.makedirs(\"/content/submission\", exist_ok=True)\n",
        "\n",
        "    # Copy notebook (if available)\n",
        "    notebook_path = f\"/content/{notebook_name}\"\n",
        "    if os.path.exists(notebook_path):\n",
        "        shutil.copy(notebook_path, \"/content/submission/\")\n",
        "    else:\n",
        "        print(\"âš ï¸ Notebook not found in /content. Please manually download and add it to your submission.\")\n",
        "\n",
        "    # Copy model files\n",
        "    shutil.copy(\"/content/rl_agent.zip\", \"/content/submission/\")\n",
        "    if os.path.exists(\"/content/rl_agent_norm.pkl\"):\n",
        "        shutil.copy(\"/content/rl_agent_norm.pkl\", \"/content/submission/\")\n",
        "\n",
        "    # Create ZIP\n",
        "    zip_name = f\"submission_package_{notebook_name.replace('.ipynb', '').replace(' ', '_')}.zip\"\n",
        "    shutil.make_archive(f\"/content/{zip_name.replace('.zip', '')}\", 'zip', \"/content/submission\")\n",
        "    files.download(f\"/content/{zip_name}\")\n"
      ],
      "metadata": {
        "id": "JXkh7fRQWHC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional Agent\n",
        "\n",
        "If you have designed a conditional agent, please follow the instructions and code cells below to test and evaluate your model.\n",
        "\n",
        "The example code provided here defines a simple conditional agent. Replace this example with your own implementation, making sure it runs correctly in the evaluation environment."
      ],
      "metadata": {
        "id": "mOp1t5lHQ_4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional agent\n",
        "\n",
        "from datetime import datetime\n",
        "from ascab.train import BaseAgent\n",
        "from ascab.env.env import AScabEnv\n",
        "\n",
        "ascab_val = gym.make('AscabValEnv-Continuous')\n",
        "\n",
        "# First define the class, not forgetting to SubClass `BaseAgent`\n",
        "# In general, you want to change the `get_action` method to apply your conditional spraying strategy\n",
        "class HowMyLocalFarmerSprays(BaseAgent):\n",
        "    def __init__(\n",
        "        self,\n",
        "        ascab: AScabEnv = None,\n",
        "        render: bool = False,\n",
        "    ):\n",
        "        super().__init__(ascab=ascab, render=render)\n",
        "\n",
        "    def get_action(self, observation: dict = None) -> float:\n",
        "        # The code below means: \"If it is forecasted that it will rain in two days, I will spray today\".\n",
        "        if self.ascab.get_wrapper_attr(\"info\")[\"Forecast_day2_HasRain\"] and self.ascab.get_wrapper_attr(\"info\")[\"Forecast_day2_HasRain\"][-1]:\n",
        "            return 1.0  # the agent sprays this much if is forecasted to rain in two days\n",
        "        return 0.0\n",
        "\n",
        "farmer_strategy = HowMyLocalFarmerSprays(ascab_val)\n",
        "\n",
        "# Use the class method below to run your agent!\n",
        "results = farmer_strategy.run()"
      ],
      "metadata": {
        "id": "1WLoBrFnz6fi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}